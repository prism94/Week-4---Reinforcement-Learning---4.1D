{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iXjp8FSQHL2d"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym.spaces import Discrete, Box\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import io\n",
    "import base64\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.animation as animation\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NaLWUx_mHTPK"
   },
   "outputs": [],
   "source": [
    "class snake(gym.Env):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.action_space = Discrete(4)\n",
    "        self.videos_images = []\n",
    "        self.snake_max_len = 100\n",
    "        self.snake_starting_length = 1\n",
    "        self.snake_length = 1\n",
    "        self.rows = 10\n",
    "        self.columns = 10\n",
    "        self.moves = [(1, 0), (0, 1), (-1, 0), (0, -1)] # 0 is down, 1 is right, 2 is up, 3 is left\n",
    "        self.default_board_environment = np.zeros((self.rows, self.columns))\n",
    "        self.board_state = self.default_board_environment\n",
    "        self.head_location = 0\n",
    "        self.apple_location = 0\n",
    "        self.videos = [('/content/snake.mp4', '/content/snake.meta.json')]\n",
    "    \n",
    "    def render_video(self):\n",
    "        lists = board.tolist()\n",
    "        for n in range(len(lists)):\n",
    "            lister = lists[n]\n",
    "            for i in range(len(lister)):\n",
    "                item = lister[i]\n",
    "                done = False\n",
    "                if item == 0:\n",
    "                    lister[i] = [0, 0, 0]\n",
    "                    done = True\n",
    "                if item == 1000:\n",
    "                    lister[i] = [255, 0, 0]\n",
    "                    done = True\n",
    "                if item == 100:\n",
    "                    lister[i] = [0, 0, 244]\n",
    "                if done == False:\n",
    "                    lister[i] = [192, 192, 192]\n",
    "            lists[n] = lister\n",
    "        self.videos_images.append(lists)\n",
    "\n",
    "    def write_video(self):\n",
    "        fig, ax = plt.subplots()\n",
    "        ims = []\n",
    "        for i in range(len(self.videos_images)):\n",
    "            im = ax.imshow(self.videos_images[i], animated=True)\n",
    "            if i == 0:\n",
    "                ax.imshow(self.videos_images[i])\n",
    "            ims.append([im])\n",
    "        ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True,\n",
    "                                        repeat_delay=1000)\n",
    "        ani.save('snake.mp4')\n",
    "        plt.close()\n",
    "        \n",
    "\n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        #Get Move\n",
    "        move = self.moves[action]\n",
    "        #Make Move\n",
    "        snake_loc = self.snake_location\n",
    "        reward = -0.05\n",
    "        cont = True\n",
    "        moving = True\n",
    "        new_length = False\n",
    "        if (snake_loc[0]+move[0]) >= self.rows:\n",
    "            cont = False\n",
    "        elif (snake_loc[0] + move[0]) < 0:\n",
    "            cont = False\n",
    "        if (snake_loc[1]+move[1]) >= self.columns:\n",
    "            cont = False\n",
    "        elif (snake_loc[1]+move[1]) < 0:\n",
    "            cont = False\n",
    "        if cont == True:\n",
    "            new_space = self.board_state[(snake_loc[0]+move[0]), (snake_loc[1]+move[1])]\n",
    "            if new_space == 1000:\n",
    "                done = True\n",
    "                reward = 1\n",
    "                new_length = True\n",
    "            if done == False:\n",
    "                if new_space != 0:\n",
    "                    if new_space != (self.snake_max_len - self.snake_length):\n",
    "                        done = True\n",
    "                        reward = -1\n",
    "        else:\n",
    "            moving = False\n",
    "            done = True\n",
    "            reward = -1\n",
    "        if moving == True:\n",
    "            moved_snake = False\n",
    "            self.board_state[(snake_loc[0]+move[0]), (snake_loc[1]+move[1])] = self.snake_max_len\n",
    "            count = self.snake_length\n",
    "            while moved_snake == False:\n",
    "                if (self.snake_max_len - count) <= (self.snake_max_len - self.snake_length):\n",
    "                    if new_length == True:\n",
    "                        find = np.where(self.board_state == (self.snake_max_len-count))\n",
    "                        self.board_state[find[0], find[1]] -= 1\n",
    "                    else:\n",
    "                        find = np.where(self.board_state == (self.snake_max_len-count))\n",
    "                        self.board_state[find[0], find[1]] = 0\n",
    "                else:\n",
    "                    find = np.where(self.board_state == (self.snake_max_len-count))\n",
    "                    self.board_state[find[0], find[1]] -= 1\n",
    "                if count == 1:\n",
    "                    moved_snake = True\n",
    "                count -= 1\n",
    "            if self.snake_length != 1:\n",
    "                self.board_state[(snake_loc[0]), (snake_loc[1])] -=1\n",
    "            else:\n",
    "                self.board_state[(snake_loc[0], (snake_loc[1]))] = 0\n",
    "            self.snake_location = [(snake_loc[0]+move[0]), (snake_loc[1]+move[1])]\n",
    "        self.render_video()\n",
    "        if done == True:\n",
    "            self.write_video()\n",
    "        return self.board_state, reward, done\n",
    "    \n",
    "    def reset(self):\n",
    "        rand_row = random.randint(0, (self.rows-1))\n",
    "        rand_col = random.randint(0, (self.columns-1))\n",
    "        #Set board space and apple\n",
    "        self.board_state = self.default_board_environment\n",
    "        self.board_state[rand_row, rand_col] = 1000\n",
    "        self.apple_location = [rand_row, rand_col]\n",
    "        #Set Snake Head location\n",
    "        snake_loc = False\n",
    "        while snake_loc == False:\n",
    "            snake_row = random.randint(0, (self.rows-1))\n",
    "            snake_col = random.randint(0, (self.columns-1))\n",
    "            if self.board_state[snake_row, snake_col] != 1000:\n",
    "                self.board_state[snake_row, snake_col] = self.snake_max_len\n",
    "                snake_loc = True\n",
    "                self.snake_location = [snake_row, snake_col]\n",
    "        #Set Snake Body Location\n",
    "        snake_length = 1\n",
    "        snake_val = self.snake_max_len\n",
    "        moves = self.moves\n",
    "        snake_built = False\n",
    "        last_row = snake_row\n",
    "        last_col = snake_col\n",
    "        if snake_length == self.snake_starting_length:\n",
    "            snake_built = True\n",
    "        while snake_built == False:\n",
    "            viable_space = []\n",
    "            for move in moves:\n",
    "                viable = True\n",
    "                if (last_row + move[0]) < 0:\n",
    "                    viable = False\n",
    "                else:\n",
    "                    if (last_row + move[0]) >= self.rows:\n",
    "                        viable = False\n",
    "                if (last_col + move[1]) < 0:\n",
    "                    viable = False\n",
    "                else:\n",
    "                    if (last_col + move[1]) >= self.columns:\n",
    "                        viable = False\n",
    "                if viable == True:\n",
    "                    if self.board_state[(last_row+move[0]), (last_col+move[1])] != 0:\n",
    "                        viable = False\n",
    "                    if viable == True:\n",
    "                        viable_space.append(move)\n",
    "            if len(viable_space) == 0:\n",
    "                breakpoint()\n",
    "            rand_move = viable_space[random.randint(0, (len(viable_space)-1))]\n",
    "            last_row = last_row + rand_move[0]\n",
    "            last_col = last_col + rand_move[1]\n",
    "            snake_val -= 1\n",
    "            self.board_state[last_row, last_col] = snake_val\n",
    "            if snake_val <= (self.snake_max_len - self.snake_starting_length):\n",
    "                snake_built = True\n",
    "        self.snake_length = self.snake_starting_length\n",
    "        return self.board_state\n",
    "    \n",
    "    def render(self, mode='human', close=False):\n",
    "        pass\n",
    "    \n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "McKFlNaG-J-v"
   },
   "source": [
    "#Markov Decision Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uQzNDBDaRQem"
   },
   "outputs": [],
   "source": [
    "def markov_decision_process(apple_coordinates, snake_coordinates):\n",
    "    rows = 10\n",
    "    cols = 10\n",
    "\n",
    "    apple_reward = 1\n",
    "\n",
    "    moves = [(1, 0), (0, 1), (-1, 0), (0, -1)]\n",
    "\n",
    "    transition_probs = {}\n",
    "    rewards = {}\n",
    "\n",
    "    r = apple_coordinates[0]\n",
    "    c = apple_coordinates[1]\n",
    "    \n",
    "    _snake_ = (snake_coordinates[0], snake_coordinates[1])\n",
    "\n",
    "    for _r_ in range(rows):\n",
    "        for _c_ in range(cols):\n",
    "            transition_probs[f'(({r}, {c}), ({_r_}, {_c_}))'] = {}\n",
    "            _move_ = []\n",
    "            i = 0\n",
    "            for move in moves:\n",
    "                new_r = _r_ + move[0]\n",
    "                new_c = _c_ + move[1]\n",
    "                cont = True\n",
    "\n",
    "                if new_r < 0:\n",
    "                    cont = False\n",
    "                elif new_r >= cols:\n",
    "                    cont = False\n",
    "                \n",
    "                if new_c < 0:\n",
    "                    cont = False\n",
    "                elif new_c >= cols:\n",
    "                    cont = False\n",
    "                \n",
    "                if cont == True:\n",
    "                    _move_.append((i, (new_r, new_c)))\n",
    "                i += 1\n",
    "            \n",
    "            for move in _move_:\n",
    "                transition_probs[f'(({r}, {c}), ({_r_}, {_c_}))'][f'{move[0]}'] = {}\n",
    "                transition_probs[f'(({r}, {c}), ({_r_}, {_c_}))'][f'{move[0]}'][f'(({r}, {c}), {move[1]})'] = 1\n",
    "    \n",
    "    #Set Rewards\n",
    "    i = 0\n",
    "    _move_ = []\n",
    "    for move in moves:\n",
    "        new_r = r - move[0]\n",
    "        new_c = c - move[1]\n",
    "\n",
    "        cont = True\n",
    "        if new_r < 0:\n",
    "            cont = False\n",
    "        elif new_r >= cols:\n",
    "            cont = False\n",
    "        \n",
    "        if new_c < 0:\n",
    "            cont = False\n",
    "        elif new_c >= cols:\n",
    "            cont = False\n",
    "        \n",
    "        if cont == True:\n",
    "            _move_.append((i, (new_r, new_c)))\n",
    "        i += 1\n",
    "    \n",
    "    for move in _move_:\n",
    "        rewards[f'(({r}, {c}), ({move[1][0]}, {move[1][1]}))'] = {}\n",
    "        rewards[f'(({r}, {c}), ({move[1][0]}, {move[1][1]}))'][f'{move[0]}'] = {f'(({r}, {c}), ({r}, {c}))':apple_reward}\n",
    "\n",
    "    init_state = f'(({r}, {c}), {_snake_})'\n",
    "    \n",
    "    mdp = MDP(transition_probs, rewards, initial_state=init_state)\n",
    "    \n",
    "    return mdp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WC9Q-e8L94v4"
   },
   "source": [
    "#Value Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KP_7y911jV_L"
   },
   "outputs": [],
   "source": [
    "def get_action_value(mdp, state_values, state, action, gamma):\n",
    "\n",
    "  q = 0\n",
    "  for _s_ in mdp.get_all_states():\n",
    "      q += mdp.get_transition_prob(state, action, _s_)*(mdp.get_reward(state, action, _s_) + gamma*state_values[_s_])\n",
    "  return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WVtCTU4DlsGj"
   },
   "outputs": [],
   "source": [
    "def get_new_state_value(mdp, state_values, state, gamma):\n",
    "    if mdp.is_terminal(state):\n",
    "        return 0\n",
    "    \n",
    "    A = [a for a in mdp.get_possible_actions(state)]\n",
    "    v = np.zeros(len(mdp.get_possible_actions(state)))\n",
    "    i = 0\n",
    "\n",
    "    for a in mdp.get_possible_actions(state):\n",
    "        v[i] = get_action_value(mdp, state_values, state, a, gamma)\n",
    "        A[i] = a\n",
    "        i += 1\n",
    "    \n",
    "    V = {A[np.argmax(v)]:v[np.argmax(v)]}\n",
    "\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J565WsEA7an9"
   },
   "outputs": [],
   "source": [
    "def get_optimal_action(mdp, state_values, state, gamma):\n",
    "  if mdp.is_terminal(state):\n",
    "      return None\n",
    "  \n",
    "  nsv = get_new_state_value(mdp, state_values, state, gamma)\n",
    "  a = list(nsv)[0]\n",
    "\n",
    "  return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KaSYEK7a9L9s"
   },
   "outputs": [],
   "source": [
    "def get_coordinates(board):\n",
    "    apple = (int(np.argmax(board)/10), np.argmax(board)%10)\n",
    "    snake = np.where(board==100)\n",
    "    snake = (snake[0][0], snake[1][0])\n",
    "    return apple, snake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZgMwzL7lenVw",
    "outputId": "1b8bfed5-d668-4ae5-dafb-2857ec4381ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    " from google.colab import drive\n",
    " import sys\n",
    " drive.mount('/content/drive')\n",
    " sys.path.insert(0,'/content/drive/MyDrive/Colab Notebooks')\n",
    " import mdp\n",
    " from mdp import MDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aobLygTx9Ivl",
    "outputId": "4aeee873-42f1-4efd-af75-94e51604f381"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates at: (2, 1) (4, 5)\n"
     ]
    }
   ],
   "source": [
    "env = snake()\n",
    "\n",
    "board = env.reset()\n",
    "\n",
    "apple_coordinates, snake_coordinates = get_coordinates(board)\n",
    "\n",
    "print( 'Coordinates at:', apple_coordinates, snake_coordinates)\n",
    "\n",
    "mdp = markov_decision_process(apple_coordinates, snake_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N0R-RMR7zv-Y"
   },
   "outputs": [],
   "source": [
    "copy_env = copy.deepcopy(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v04IGDt4rX63",
    "outputId": "91b4b709-e4c1-42ec-aa5b-363f012d98a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0 diff: 1.0\n",
      "iter 1 diff: 0.9\n",
      "iter 2 diff: 0.81\n",
      "iter 3 diff: 0.7290000000000001\n",
      "iter 4 diff: 0.6561000000000001\n",
      "iter 5 diff: 0.5904900000000002\n",
      "iter 6 diff: 0.5314410000000002\n",
      "iter 7 diff: 0.47829690000000014\n",
      "iter 8 diff: 0.4304672100000002\n",
      "iter 9 diff: 0.38742048900000037\n",
      "iter 10 diff: 0.3486784401000005\n",
      "iter 11 diff: 0.3138105960900004\n",
      "iter 12 diff: 0.28242953648100055\n",
      "iter 13 diff: 0.2541865828329004\n",
      "iter 14 diff: 0.2287679245496106\n",
      "iter 15 diff: 0.20589113209464938\n",
      "iter 16 diff: 0.1853020188851845\n",
      "iter 17 diff: 0.1667718169966661\n",
      "iter 18 diff: 0.1500946352969995\n",
      "iter 19 diff: 0.13508517176729962\n",
      "iter 20 diff: 0.12157665459056965\n",
      "iter 21 diff: 0.10941898913151271\n",
      "iter 22 diff: 0.0984770902183616\n",
      "iter 23 diff: 0.08862938119652597\n",
      "iter 24 diff: 0.0797664430768732\n",
      "iter 25 diff: 0.07178979876918579\n",
      "iter 26 diff: 0.06461081889226716\n",
      "iter 27 diff: 0.0581497370030406\n",
      "iter 28 diff: 0.052334763302736675\n",
      "iter 29 diff: 0.047101286972462963\n",
      "iter 30 diff: 0.04239115827521678\n",
      "iter 31 diff: 0.0381520424476951\n",
      "iter 32 diff: 0.034336838202925435\n",
      "iter 33 diff: 0.030903154382633247\n",
      "iter 34 diff: 0.027812838944369922\n",
      "iter 35 diff: 0.02503155504993293\n",
      "iter 36 diff: 0.02252839954493968\n",
      "iter 37 diff: 0.020275559590445802\n",
      "iter 38 diff: 0.01824800363140122\n",
      "iter 39 diff: 0.01642320326826119\n",
      "iter 40 diff: 0.014780882941435092\n",
      "iter 41 diff: 0.01330279464729145\n",
      "iter 42 diff: 0.011972515182562482\n",
      "iter 43 diff: 0.010775263664306145\n",
      "iter 44 diff: 0.009697737297875486\n",
      "iter 45 diff: 0.008727963568088137\n",
      "iter 46 diff: 0.007855167211279213\n",
      "iter 47 diff: 0.007069650490151513\n",
      "iter 48 diff: 0.006362685441136273\n",
      "iter 49 diff: 0.005726416897022801\n",
      "iter 50 diff: 0.005153775207320521\n",
      "iter 51 diff: 0.004638397686588469\n",
      "iter 52 diff: 0.004174557917929755\n",
      "iter 53 diff: 0.003757102126136669\n",
      "iter 54 diff: 0.0033813919135230464\n",
      "iter 55 diff: 0.003043252722171097\n",
      "iter 56 diff: 0.002738927449954076\n",
      "iter 57 diff: 0.002465034704958402\n",
      "iter 58 diff: 0.002218531234462695\n",
      "iter 59 diff: 0.0019966781110163367\n",
      "iter 60 diff: 0.0017970102999149695\n",
      "iter 61 diff: 0.0016173092699234282\n",
      "iter 62 diff: 0.0014555783429310853\n",
      "iter 63 diff: 0.0013100205086380434\n",
      "iter 64 diff: 0.0011790184577744611\n",
      "iter 65 diff: 0.0010611166119969262\n",
      "iter 66 diff: 0.0009550049507973668\n",
      "Min Difference\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.9\n",
    "iter = 100\n",
    "min_difference = 0.001\n",
    "\n",
    "state_values = {s:0 for s in mdp.get_all_states()}\n",
    "\n",
    "for i in range(iter):\n",
    "    new_state_vals = {}\n",
    "    for _s_ in mdp.get_all_states():\n",
    "        nsv = get_new_state_value(mdp, state_values, _s_, gamma)\n",
    "        a = list(nsv)[0]\n",
    "        v = nsv[a]\n",
    "        new_state_vals[_s_] = v\n",
    "    \n",
    "    diff = max(abs(new_state_vals[_s_] - state_values[_s_]) for _s_ in mdp.get_all_states())\n",
    "    state_values = new_state_vals\n",
    "\n",
    "    print(f'iter {i} diff: {diff}')\n",
    "\n",
    "    if diff < min_difference:\n",
    "        print('Min Difference')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "id": "zX7r0iRGHVuX",
    "outputId": "113c5bfc-bc86-4e61-c2ed-b1b5dae1daba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Finished reward: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <video alt=\"test\" controls>\n",
       "        <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "        </video>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "value_reward = []\n",
    "for _ in range(100):\n",
    "    apple_coordinates, snake_coordinates = get_coordinates(board)\n",
    "    policy = get_optimal_action(mdp, state_values, f'({apple_coordinates}, {snake_coordinates})', gamma)\n",
    "    #policy = int(input()) # 0 is down, 1 is right, 2 is up, 3 is left3\n",
    "    board, reward, done = env.step(int(policy))\n",
    "    value_reward.append(reward)\n",
    "    if done == True:\n",
    "        print(f'Game Finished reward: {reward}')\n",
    "        break\n",
    "    if _ > 100:\n",
    "        print('Time Exceeded')\n",
    "        break\n",
    "\n",
    "for f in env.videos:\n",
    "    video = io.open(f[0], 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "\n",
    "    display.display(display.HTML(data=\"\"\"\n",
    "        <video alt=\"test\" controls>\n",
    "        <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "        </video>\n",
    "        \"\"\".format(encoded.decode('ascii'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jfQzPa6k5sPe"
   },
   "source": [
    "#Policy Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "COrFsLgfwbYR"
   },
   "outputs": [],
   "source": [
    "def policy_evaluation(mdp, state_values, gamma):\n",
    "    \n",
    "    new_state_values = copy.deepcopy(state_values)\n",
    "    state_check = False\n",
    "\n",
    "    while state_check == False:\n",
    "        value_change = False\n",
    "        for _s_ in mdp.get_all_states():\n",
    "            q = new_state_values[_s_]['Value']\n",
    "            _q_ = 0\n",
    "            for action in state_values[_s_]['Actions'].keys():\n",
    "                policy = new_state_values[_s_]['Actions'][action]\n",
    "                leading_states = mdp.get_next_states(_s_, action)\n",
    "                for _state_ in leading_states.keys():\n",
    "                    _q_ += policy*mdp.get_transition_prob(_s_, action, _state_)*(mdp.get_reward(_s_, action, _state_) + gamma*new_state_values[_state_]['Value'])\n",
    "            new_state_values[_s_]['Value'] = _q_\n",
    "            if q != _q_:\n",
    "                value_change = True\n",
    "        if value_change == False:\n",
    "            state_check = True\n",
    "       \n",
    "    return new_state_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R_ClW0K-71Uy"
   },
   "outputs": [],
   "source": [
    "def policy_improvement(mdp, s_values, gamma):\n",
    "    new_state_values = copy.deepcopy(s_values)\n",
    "    same_check = True\n",
    "\n",
    "    for state in new_state_values:\n",
    "        max_value = -10000\n",
    "        best_actions = []\n",
    "        for action in new_state_values[state]['Actions'].keys():\n",
    "            policy = new_state_values[state]['Actions'][action]\n",
    "            leading_states = mdp.get_next_states(state, action)\n",
    "            _q_ = 0\n",
    "            for _state_ in leading_states.keys():\n",
    "                _q_ += mdp.get_transition_prob(state, action, _state_)*(mdp.get_reward(state, action, _state_) + gamma*new_state_values[_state_]['Value'])\n",
    "            if _q_ > max_value:\n",
    "                max_value = _q_\n",
    "                best_actions = [action]\n",
    "            else:\n",
    "                if _q_ == max_value:\n",
    "                    best_actions.append(action)\n",
    "        \n",
    "        for action in new_state_values[state]['Actions'].keys():\n",
    "            if action in best_actions:\n",
    "                policy = 1/len(best_actions)\n",
    "            else:\n",
    "                policy = 0\n",
    "            if policy != new_state_values[state]['Actions'][action]:\n",
    "                same_check = False\n",
    "            new_state_values[state]['Actions'][action] = policy\n",
    "    \n",
    "    return new_state_values, same_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nrlfD1gbZNNY"
   },
   "outputs": [],
   "source": [
    "def get_optimal_action(s_values, state):\n",
    "    \n",
    "    opt_action = None\n",
    "    rand = random.uniform(0, 1)\n",
    "    value = 0\n",
    "    \n",
    "    for action in s_values[state]['Actions'].keys():\n",
    "        value += s_values[state]['Actions'][action]\n",
    "        if value > rand:\n",
    "            opt_action = action\n",
    "            break\n",
    "\n",
    "    return opt_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-kyAQmkpuQHq"
   },
   "outputs": [],
   "source": [
    "def initialise_state_values():\n",
    "    state_values = {}\n",
    "    for state in mdp.get_all_states():\n",
    "        s = {'Value':0}\n",
    "        actions = []\n",
    "        for action in mdp.get_possible_actions(state):\n",
    "            actions.append(action)\n",
    "        s['Actions'] = {}\n",
    "        for action in actions:\n",
    "            s['Actions'][action] = 1/len(actions)\n",
    "        state_values[state] = s\n",
    "    return state_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LvpzyvGK6AfL",
    "outputId": "79475e80-e85a-4f00-9e98-6e1e5fb11ac1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates at: (2, 1) (4, 5)\n"
     ]
    }
   ],
   "source": [
    "env = copy_env\n",
    "\n",
    "board = env.board_state\n",
    "\n",
    "apple_coordinates, snake_coordinates = get_coordinates(board)\n",
    "\n",
    "print( 'Coordinates at:', apple_coordinates, snake_coordinates)\n",
    "\n",
    "mdp = markov_decision_process(apple_coordinates, snake_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8R8_LKjbue5F"
   },
   "outputs": [],
   "source": [
    "state_values = initialise_state_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "byavO4qmw2_p",
    "outputId": "496421b1-c703-4100-942a-dd95fa35702e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Convergence Complete\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.9\n",
    "\n",
    "#Initialisation\n",
    "state_values = initialise_state_values()\n",
    "\n",
    "convergence = False\n",
    "\n",
    "iter = 1\n",
    "\n",
    "while convergence == False:\n",
    "    #Policy Evaluation\n",
    "    state_values = policy_evaluation(mdp, state_values, gamma)\n",
    "\n",
    "    #Policy Improvement\n",
    "    state_values, convergence = policy_improvement(mdp, state_values, gamma)\n",
    "\n",
    "    print(f'Iteration: {iter}')\n",
    "    iter += 1\n",
    "    \n",
    "    if convergence == True:\n",
    "        print('Convergence Complete')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rgwBdVRBZBbt",
    "outputId": "ece99fc3-129f-40a6-a10c-7d878fcbd9fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1) (4, 5)\n",
      "((2, 1), (4, 5))\n"
     ]
    }
   ],
   "source": [
    "apple_coordinates, snake_coordinates = get_coordinates(board)\n",
    "print(apple_coordinates, snake_coordinates)\n",
    "print(f'({apple_coordinates}, {snake_coordinates})')\n",
    "initial_state = f'({apple_coordinates}, {snake_coordinates})'\n",
    "apple_loc = f'({apple_coordinates}, {apple_coordinates})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "id": "toNi2Bhl6jmr",
    "outputId": "ce2e0a0d-5acf-4c25-fb6c-0a4b68070b3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Finished reward: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <video alt=\"test\" controls>\n",
       "        <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAACLJtZGF0AAACrgYF//+q3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1MiByMjg1NCBlOWE1OTAzIC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxNyAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MzoweDExMyBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MSBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD0tMiB0aHJlYWRzPTMgbG9va2FoZWFkX3RocmVhZHM9MSBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRlcmxhY2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJfcHlyYW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9MCB3ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTIwIHNjZW5lY3V0PTQwIGludHJhX3JlZnJlc2g9MCByY19sb29rYWhlYWQ9NDAgcmM9Y3JmIG1idHJlZT0xIGNyZj0yMy4wIHFjb21wPTAuNjAgcXBtaW49MCBxcG1heD02OSBxcHN0ZXA9NCBpcF9yYXRpbz0xLjQwIGFxPTE6MS4wMACAAAAEPGWIhAA3//728P4FNjuY0JcRzeidMx+/Fbi6NDe9zgAAAwAAN9zmRP7KkwbmwAAC4SdPkc138wBDfbLdp6TC6MUdw0FoUWOaOLequERzXY4BCbFlLIVfnPNwU0C4K9C8aRLadKwbrc08HEQ8NeAwfc4r4NZ7kDz7uZNv04oCBa+h+vw12DwpsNHRPxJuKTSFk+NvBUv8DBP1Lz0JBftae/cCcxLsZbWg6YR5MAr0P57+FFY/ZzXr2Ndycv5uR0I/bKFVnkD/9SDfxl+5PzPyWK/4tiuaVwY8aJpdswSITL7lBEAHJg5WdEBfBPEZaJIk96qDdLt2Lv5/B9CcfD+qWdtYcbNZpv66hC6DS3G+zUw/zHsI0j9UttPeB9pumOKAjSMT+tkNfaQeCUNCl9Sq24AB6+XKBb1iP2Att4q88JblBHd+veTUh6iEEL424iuayShsv0qlIbF2VtKq4AKFAP66w8ivBODoGRr8CJYlHnqhXn0bAN84gTjhaBEQhu3vrqWX+UoKI5Qla/9klp//E3TShS+AcgnWTZ1vgL0F8YgiAtifVSY697RDiUoncTc3J4dhiqiv78rSB8e2/0CQTPSSGpCZh1eiotdR9+dcI2QkQXlCMPy0nWsgW/v9c1IoeLh/6pWROVFuezbySu+3goUBqP27iIpToppED4Vaf7ZSHNZDIaXIJM3jyd5UIjv7TBacaIawQCZhe8Tb0fhSV/84E6kPYTyXj937rUwyRd/xBMo2mHvDg4zSps+Q7mNo6IBgYgIL4z1aQ9u09S6N/cBCjbfnmgS0DwmAxZ5OeXr1cIas7V4ZLLIccS2V+/AooNhdOXHs6Or6F7Euhkx1lHSKD9FCldRDnIu4YqugJjbRa78eZTsqgfjPKABARQ7TepDqGEl8Re7s+nTsalv+3RwJKSPzlhGpxSMoAJR5TurYuY74Vc8CRXQUH6d9chOUXxemHHsCqCBnZBc+g5vcwVq3JRTkx6LD+dg+N+Ghnp53T007HEeOZewQ6yWtl0UjIA3EqQxtME72DHUS4MACExPDWEaNYieQDrUOaEAg4ePbE+uVXwiOLtNZuGiffjwjfguQEVhW57Dekpxgvcydvqh6PSqEmCiHlt7dq0X18FwO9iQEUIJ3m+Mu9OUyCPJCvi0uUr3W8MPefPBS3TWMrInOIxRo++Oltk21iB7fPwitwcoN51YyyIlo+T16K3bmA9k05+xXUhFRmnc9YMgr2An2eHV63ii2xCku1sS33DoHLDL4Lq5XI+FdWwlRXEHeYPtex+9SOaV+bpj+tZhVPeOGwTInWqWu+mMiSLjRCs/DoNmVa/IebIJm99orJO+H1PsjHImR+tNIniVWl3txGow92DblX2/ydpA/gPRRGo9AdVtl6fnWU4uo9GYOe5aqb8hO9v00v2uR8tfupXfLRVjkXE6wSaLsA972E7EAAACTQZohbEN//qeEABfdC2wANBEJDTFcM4C/gYQsEmf+3+zm1hOmVRqcYcFWY71ug1l3omf+Y546A5pBoa12q8K7TFtNlZAQdy+Xxluem8dlpfsr77ypYJhtUu5PF4hkx/DkznZK+jkmZMPrLxJsGzwfoyEoG0+b5g5KMKsVJ1rnbLz+DvEFl74qN8Uaq859IX0Zk9oWAAAANkGaQjwhkymEM//+nhAAWI2J4Zic/f4sec2GgzBuiCZ8+Pq/SR6TuVBRAEIBmb6oAVf/uN4zOwAAAC5BmmNJ4Q8mUwIZ//6eEAFh4M3fTP0BACWSPYZ/aDKIwhWovvMR8BDFL16HdB9gAAAAYkGahEnhDyZTAhn//p4QAXOsVuOAE1eSy1jKZACLVRh0Rbn1ZI4VZUxUZf+d77qOk3izI+R1uV3Ag38v+CKlumq53aXDDG/GDfWBejtra2dahspbrC+obWpDqKYWoGhiqEpJAAAAS0GapUnhDyZTAhX//jhABdd2+CY2CQAt40qHro61cmnO4zGt/Gr3N5p7D0ofo9/otsFo8jgkh/waKdh0KiPUX4ExhUrK/gNirHfxEQAAAzJtb292AAAAbG12aGQAAAAAAAAAAAAAAAAAAAPoAAABLAABAAABAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAAACXHRyYWsAAABcdGtoZAAAAAMAAAAAAAAAAAAAAAEAAAAAAAABLAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAABsAAAASAAAAAAACRlZHRzAAAAHGVsc3QAAAAAAAAAAQAAASwAAAQAAAEAAAAAAdRtZGlhAAAAIG1kaGQAAAAAAAAAAAAAAAAAACgAAAAMAFXEAAAAAAAtaGRscgAAAAAAAAAAdmlkZQAAAAAAAAAAAAAAAFZpZGVvSGFuZGxlcgAAAAF/bWluZgAAABR2bWhkAAAAAQAAAAAAAAAAAAAAJGRpbmYAAAAcZHJlZgAAAAAAAAABAAAADHVybCAAAAABAAABP3N0YmwAAACXc3RzZAAAAAAAAAABAAAAh2F2YzEAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAABsAEgAEgAAABIAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY//8AAAAxYXZjQwFkABX/4QAYZ2QAFazZQbCWhAAAAwAEAAADAKA8WLZYAQAGaOvjyyLAAAAAGHN0dHMAAAAAAAAAAQAAAAYAAAIAAAAAFHN0c3MAAAAAAAAAAQAAAAEAAAAYY3R0cwAAAAAAAAABAAAABgAABAAAAAAcc3RzYwAAAAAAAAABAAAAAQAAAAYAAAABAAAALHN0c3oAAAAAAAAAAAAAAAYAAAbyAAAAlwAAADoAAAAyAAAAZgAAAE8AAAAUc3RjbwAAAAAAAAABAAAAMAAAAGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAAAAAAAAAALWlsc3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZmNTcuODMuMTAw\" type=\"video/mp4\" />\n",
       "        </video>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "policy_reward = []\n",
    "for _ in range(100):\n",
    "    apple_coordinates, snake_coordinates = get_coordinates(board)\n",
    "    policy = get_optimal_action(state_values, f'({apple_coordinates}, {snake_coordinates})')\n",
    "    #policy = int(input()) # 0 is down, 1 is right, 2 is up, 3 is left3\n",
    "    board, reward, done = env.step(int(policy))\n",
    "    policy_reward.append(reward)\n",
    "    if done == True:\n",
    "        print(f'Game Finished reward: {reward}')\n",
    "        break\n",
    "    if _ > 100:\n",
    "        print('Time Exceeded')\n",
    "        break\n",
    "\n",
    "for f in env.videos:\n",
    "    video = io.open(f[0], 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "\n",
    "    display.display(display.HTML(data=\"\"\"\n",
    "        <video alt=\"test\" controls>\n",
    "        <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "        </video>\n",
    "        \"\"\".format(encoded.decode('ascii'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NyD4aQoc7kwq",
    "outputId": "0bc928f9-e649-4b8f-8178-243c7913e559"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Iteration Reward: 0.125\n",
      "Policy Iteration Reward: 0.125\n"
     ]
    }
   ],
   "source": [
    "print(f'Value Iteration Reward: {np.array(value_reward).mean()}')\n",
    "print(f'Policy Iteration Reward: {np.array(policy_reward).mean()}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "4-1D.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
